{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# set seed value\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "\n",
    "print(\"학습셋 이미지 수: %d 개\" % (X_train.shape[0]))\n",
    "print(\"테스트셋 이미지 수: %d 개\" % (X_test.shape[0]))\n",
    "X_train = X_train.reshape(X_train.shape[0], 28,28,1)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_train = X_train / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28,28,1).astype(\"float32\") / 255\n",
    "Y_train = np_utils.to_categorical(Y_class_train)\n",
    "Y_test = np_utils.to_categorical(Y_class_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "학습셋 이미지 수: 60000 개\n",
      "테스트셋 이미지 수: 10000 개\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "MODEL_DIR = \"./model/\"\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# cpu 혼자만으로 감당을 못하기에 gpu 환경에서 꼭 실행해야됨\n",
    "tf.config.run_functions_eagerly(True)\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback, checkpointer])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4211: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05392, saving model to ./model/01-0.0539.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05392 to 0.04012, saving model to ./model/02-0.0401.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04012 to 0.03305, saving model to ./model/03-0.0330.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03305 to 0.03224, saving model to ./model/04-0.0322.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03224\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03224 to 0.02926, saving model to ./model/06-0.0293.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02926\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02926\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02926\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02926 to 0.02887, saving model to ./model/10-0.0289.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02887\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02887 to 0.02827, saving model to ./model/12-0.0283.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02827 to 0.02660, saving model to ./model/13-0.0266.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02660 to 0.02410, saving model to ./model/14-0.0241.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02410\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02410\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_vloss = history.history[\"val_loss\"]\n",
    "\n",
    "y_loss = history.history[\"loss\"]\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker=\".\", c=\"red\", label=\"Testset_loss\")\n",
    "\n",
    "plt.plot(x_len, y_loss, marker=\".\", c=\"blue\", label=\"Trainset_loss\")\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}